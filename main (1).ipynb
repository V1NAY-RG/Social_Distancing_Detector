{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e10dd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "#importing modules cv2 is one of the modules in opencv which is used for mainly detection purpose\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg.txt\")\n",
    "classes = [\"person\"]\n",
    "with open(\"coco.names.txt\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "print(classes)\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4763b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i-1] for i in net.getUnconnectedOutLayers()] \n",
    "np.random.uniform(0,255,size=(len(classes),3))\n",
    "cap = cv2.VideoCapture('walking.mp4')\n",
    "#if you want to access your camera then give the code has cap = cv2.VideoCapture(0)\n",
    "#or if we want to access a other camera like cctv we can give the above command and pass an ip address as parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8564c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Start working on video\n",
    "while(cap.isOpened()):\n",
    "    ret,img = cap.read()\n",
    "    print(ret)\n",
    "    if not ret:\n",
    "        break\n",
    "    width = None\n",
    "    if width is None or height is None:\n",
    "        height,width = img.shape[:2]\n",
    "        q=width\n",
    "    img =  img[0:height,0:q]\n",
    "    height,width = img.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(img,0.00392,(416,416),(0,0,0),True,crop = False)\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    outs = net.forward(output_layers)\n",
    "    end = time.time()\n",
    "    #converting the mp4 format to the python compatible by using blob\n",
    "    class_ids=[]\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence>0.5:\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h=int(detection[3]*height)\n",
    "                x= int(center_x -w/2)\n",
    "                y=int(center_y -h /2)\n",
    "                boxes.append([x,y,w,h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    #helps in object detection\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.5)#removes more number of boxex on the same objects\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    if len(indexes)>0:\n",
    "        status = list()\n",
    "        idf = indexes.flatten()\n",
    "        close_pair=list()\n",
    "        s_close_pair=list()\n",
    "        center = list()\n",
    "        dist =list()\n",
    "        for i in idf:\n",
    "            (x,y) = (boxes[i][0], boxes[i][1])\n",
    "            (w,h) = (boxes[i][2],boxes[i][3])\n",
    "                #cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                #cv2.putText(img,label,(x,y+30),font,1,(255,0,0),2)\n",
    "            center.append([int(x+w/2), int(y+h/2)])\n",
    "            status.append(0)\n",
    "        for i in range(len(center)):\n",
    "            for j in range(len(center)):\n",
    "                g=isclose(center[i],center[j])\n",
    "                if g==1:\n",
    "                    close_pair.append([center[i],center[j]])\n",
    "                    status[i]=1\n",
    "                    status[j]=1\n",
    "                elif g==2:\n",
    "                    s_close_pair.append([center[i],center[j]])\n",
    "                    if status[i] !=1:\n",
    "                        status[i]=2\n",
    "                    if status[j] !=1:\n",
    "                        status[j] = 2\n",
    "                        \n",
    "        total_p=len(center)\n",
    "        low_risk_p= status.count(2)\n",
    "        high_risk_p= status.count(1)\n",
    "        safe_p = status.count(0)\n",
    "        kk=0\n",
    "        for i in idf:\n",
    "            sub_img=img[10:170,10:width-10]\n",
    "            black_rect = np.ones(sub_img.shape,dtype=np.uint8)*0\n",
    "            res = cv2.addWeighted(sub_img, 0.77,black_rect,0.23,1.0)\n",
    "            img[10:170,10:width -10] = res\n",
    "            cv2.putText(img,\"Social Distancing Detection\",(400,45),font,1,(255,255,255),2)\n",
    "            cv2.rectangle(img,(20,60),(625,160),(170,170,170),2)\n",
    "            cv2.putText(img,\"Connecting lines shows closeness among people\",(45,80),font,0.6,(255,255,0),1)\n",
    "            cv2.putText(img,\"YELLOW :CLOSE\",(45,110),font,0.5,(0,255,255),1)\n",
    "            cv2.putText(img,\"RED :VERY CLOSE\",(45,130),font,0.5,(0,0,255),1)\n",
    "            cv2.rectangle(img,(675,60),(width -20,160),(170,170,170),2)\n",
    "            cv2.putText(img,\"Bounding box shows the level of risk to the person\",(685,80),font,0.6,(255,255,0),1)\n",
    "            cv2.putText(img,\"DARK RED:HIGH RISK\",(685,110),font,0.5,(0,0,150),1)\n",
    "            cv2.putText(img,\"ORANGE: LOW RISK\",(685,130),font,0.5,(0,120,255),1)\n",
    "            cv2.putText(img,\"GREEN :CONGRATULATIONS YOU ARE SAFE\",(685,150),font,0.5,(0,255,0),1)\n",
    "            tot_str = \"NUMBER OF PEOPLE:\"+str(total_p)\n",
    "            high_str = \"Red ZONE:\" +str(high_risk_p)\n",
    "            low_str = \"ORANGE ZONE:\" +str(low_risk_p)\n",
    "            safe_str = \"GREEN ZONE:\" +str(safe_p)\n",
    "            sub_img = img[height-120:height-20,0:500]\n",
    "            black_rect = np.ones(sub_img.shape,dtype=np.uint8)*0\n",
    "            res = cv2.addWeighted(sub_img,0.8,black_rect,0.2,1.0)\n",
    "            img[height - 120:height-20,0:500]= res\n",
    "            cv2.putText(img,tot_str,(10,height -75),font,0.6,(255,255,255),1)\n",
    "            cv2.putText(img,safe_str,(300,height -75),font,0.6,(0,255,0),1)\n",
    "            cv2.putText(img,low_str,(10,height -50),font,0.6,(0,120,255),1)\n",
    "            cv2.putText(img,high_str,(300,height - 50),font,0.6,(0,0,150),1)\n",
    "            (x,y) = (boxes[i][0], boxes[i][1])\n",
    "            (w,h) = (boxes[i][2],boxes[i][3])\n",
    "            if status[kk]==1:\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,150),2)\n",
    "            elif status[kk]==0:\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            else:\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(0,120,255),2)\n",
    "            kk += 1\n",
    "            for h in close_pair:\n",
    "                cv2.line(img,tuple(h[0]),tuple(h[1]),(0,0,255),2)\n",
    "            for b in close_pair:\n",
    "                cv2.line(img,tuple(b[0]),tuple(b[1]),(0,255,255),2)\n",
    "    cv2.imshow('image',img)\n",
    "    if cv2.waitKey(1)& 0xFF == ord('q'):\n",
    "        break\n",
    "    cv2.waitKey(1)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    output = cv2.VideoWriter('output4.mp4',fourcc,20.0,(img.shape[1],img.shape[0]))\n",
    "    output.write(img)\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5deccc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrated_dist(p1,p2):#used to calculate the euclidian distance in the video in the pixel format\n",
    "    return ((p1[0]-p2[0])**2 +(p1[1]-p2[1])**2)**0.5\n",
    "def isclose(p1,p2):\n",
    "    c_d = calibrated_dist(p1,p2)\n",
    "    calib=(p1[1]+p2[1])/2\n",
    "    if 0<c_d <0.15*calib:\n",
    "        return 1#danger\n",
    "    elif 0 < c_d < 0.2*calib:\n",
    "        return 2#low risk\n",
    "    else:\n",
    "        return 0#Safe\n",
    "height,width=(None,None)\n",
    "\n",
    "q=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea6fa91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a011b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912e8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802e6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd42a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76439c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd51ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f184c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
